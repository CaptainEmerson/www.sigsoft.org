<p>Over the last decade, research has highlighted the importance of integrating the performance analysis in the software development process. Software Performance Engineering (SPE) has been recognized as the discipline that represents the entire collection of engineering activities, used throughout the software development cycle, and directed to meet performance requirements. Performance is in fact an essential quality attribute of every software system, it is a complex and a pervasive property difficult to understand. If performance targets are not met, a variety of negative consequences (such as damaged customer relations, business failures, lost income, etc.) can impact on a significant fraction of projects. Performance problems cause delays, failures on deployment, redesigns, even a new implementation of the system or abandonment of projects, which lead to significant costs.</p>

<p>All these factors motivate the activities of modeling and analyzing the performance of software systems at the earlier phases of the lifecycle by reasoning on predictive quantitative results in order to avoid an expensive rework, possibly involving the overall software system. To this purpose, many model-based performance analysis techniques have been successfully proposed. Nevertheless, the problem of interpreting the results of performance analysis is still critical in the software performance domain: mean values, variances, and probability distributions are hard to interpret for providing feedback to software architects. Support to the interpretation of performance analysis results that helps to fill the gap between numbers and architectural alternatives is still lacking.</p>

<p>The aim of this thesis is to provide an automated feedback to make the performance analysis results usable at the software architectural level. We devise a methodology to keep track of the performance knowledge that usually tends to be fragmented and quickly lost. The purpose is to interpret the performance analysis results and to suggest the most suitable architectural reconfigurations, while the development progresses. The framework we propose is aimed at addressing this problem with performance antipatterns that are recurring solutions to common mistakes (i.e. bad practices) affecting performance. Such antipatterns can play a key role in the software performance domain, because they can be used in the search of performance problems as well as in the formulation of solutions in terms of architectural alternatives. The approach we propose is validated with two case studies:</p>
<p>&nbsp;&nbsp;(i) E-Commerce system, modeled with UML, where the performance model has been analytically solved;</p>
<p>&nbsp;(ii) Business Reporting system, modeled with the Palladio Component Model, where the performance analysis has been conducted through simulation.</p>
<p>Experimental results finally demonstrate its applicability and validity.</p>
